{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `MODEL` is the huggingface repo that will be downloaded from.\n",
    "- `CUDA` defines whether CUDA will be used for `input_ids` (significant speedup on NVIDIA GPUs).\n",
    "- `USER` defines the user tag (usage defined in `ROLE`).\n",
    "- `ASSISTANT` defines the assistant tag (usage defined in `ROLE`).\n",
    "- `START_HEADER` defines the start of the header tag (usage defined in `ROLE`).\n",
    "- `END_HEADER` defines the end of the header tag (usage defined in `ROLE`).\n",
    "- `ROLE` is a function for concatenating the header tags.\n",
    "- `START_TEXT` defines the start of the text tag (usage defined in `TEXT`).\n",
    "- `END_TEXT` defines the end of the text tag (usage defined in `TEXT`).\n",
    "- `TEXT` is a function for concatenating the text tags.\n",
    "- `IMAGE` defines the image tag, leave blank for non-vision models.\n",
    "- `prompt` defines the beginning of the prompt, leave blank for no start tag.\n",
    "- `image` should be untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\"\n",
    "CUDA=True\n",
    "USER=\"user\"\n",
    "ASSISTANT=\"assistant\"\n",
    "START_HEADER=\"<|start_header_id|>\"\n",
    "END_HEADER=\"<|end_header_id|>\\n\\n\"\n",
    "ROLE = lambda str : START_HEADER + str + END_HEADER\n",
    "START_TEXT=\"\"\n",
    "END_TEXT=\"<|eot_id|>\"\n",
    "TEXT = lambda str : START_TEXT + str + END_TEXT\n",
    "IMAGE=\"<|image|>\"\n",
    "prompt = \"<|begin_of_text|>\"\n",
    "image=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(MODEL)\n",
    "model = AutoModelForImageTextToText.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(msg, images):\n",
    "    global prompt\n",
    "    global image\n",
    "\n",
    "    prompt += ROLE(USER)\n",
    "    for imgobj in images:\n",
    "        prompt += IMAGE\n",
    "        image.append(imgobj)\n",
    "    prompt += TEXT(msg)\n",
    "    prompt += ROLE(ASSISTANT)\n",
    "\n",
    "    inputs = None\n",
    "    if len(image) > 0:\n",
    "        inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    else:\n",
    "        inputs = processor(text=prompt, return_tensors=\"pt\")\n",
    "\n",
    "    if CUDA:\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "\n",
    "    output = model.generate(**inputs, max_new_tokens=256)\n",
    "\n",
    "    prompt_len = inputs.input_ids.shape[-1]\n",
    "    generated_ids = output[:, prompt_len:]\n",
    "    generated_text = processor.batch_decode(generated_ids, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    prompt += generated_text[-1]\n",
    "\n",
    "    return generated_text[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGEXPR = r\"\\\"?[ABCDEFGH]:[\\\\/].+?\\..+?[\\\" ]\"\n",
    "\n",
    "while True:\n",
    "    msg = input()\n",
    "\n",
    "    imagepaths = re.findall(REGEXPR, msg)\n",
    "    images = []\n",
    "    for path in imagepaths:\n",
    "        images.append(Image.open(path.replace(\"\\\"\",\"\")))\n",
    "    msg = re.sub(REGEXPR, \"\", msg)\n",
    "\n",
    "    output = generate(msg, images)\n",
    "\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
